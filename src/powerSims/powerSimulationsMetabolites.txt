# this power simulation assumes perfectly a normal distribution 
# and then applies a t-test.
# Real data, of course, are likely to have a different distribution
# so these results should be considered a rough approximation

rm(list=ls())
sampleSizeForEachGroup <- 40
numHypotheses <- 500
numUnder <- 0
numBonferroniUnder <-0
fractionTruePositives <- 0.25
numTruePositves <-0;
effectSize <- 1.38

pValues <- vector();
truePositives <- vector()

for( j in 1 : numHypotheses ) 
{
	isATruePositive <- ( runif(1) <= fractionTruePositives )

	if( isATruePositive ) 	
		numTruePositves= numTruePositves + 1

	data<-vector()
	data2<-vector()

	for( i in 1 : sampleSizeForEachGroup)
	{
		data[i] = rnorm(1)
	
		if( isATruePositive  ) 
		{
			data2[i] = rnorm(1, mean=effectSize)
		}
		else
		{
			data2[i] = rnorm(1)
		}
	}
	
	pValues[j] <- t.test(data,data2)$p.value 
	truePositives[j] <- isATruePositive
	
	if( isATruePositive  & pValues[j] < 0.05 )
		numUnder = numUnder + 1
	
	if( isATruePositive  & pValues[j] < 0.05 / numHypotheses )
		numBonferroniUnder = numBonferroniUnder + 1	
	
	
}

numTruePositves
numUnder/numTruePositves
numBonferroniUnder /numTruePositves

myFrame <- data.frame(pValues,truePositives  )
myFrame<- myFrame [order(myFrame$pValues),]
myFrame$pAdjust <- p.adjust(myFrame$pValues, method="BH")
myFrame$Bonf <- p.adjust(myFrame$pValues, method="bonferroni")

bhUnder <- 0;

for( i in 1:nrow(myFrame))
{
	if( myFrame$truePositives[i] & myFrame$pAdjust[i] < 0.10  )
		bhUnder <- bhUnder + 1;
}

bhUnder / numTruePositves
